#!/usr/bin/env node
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

const argSplit = require('argv-split');
const commander = require('commander');
const CrawlerClient = require('../lib/crawlerClient');
const readline = require('readline');
const Q = require('q');
const qlimit = require('qlimit');
const request = require('request');
const split = require('split');

const crawlerClient = new CrawlerClient();
let promise = Q();

const commands = getCommands();
if (!process.argv.slice(2).length) {
  commands.help();
}
commands.parse(process.argv);
promise.then(() => {
  if (commands.interactive) {
    startReplLoop(commands);
  }
});

function getCommands() {
  const commands = new commander.Command()
  commands
    .version('0.0.1')
    .option('-i, --interactive', 'Run in interactive mode. Otherwise the given command is executed and this tool exits.')
    .option('-s, --service <url>', 'URL of the crawler service', url => crawlerClient.url = url)
    .option('-t, --token <token>', 'Token for talking to the crawler service', token => crawlerClient.authToken = token);
  commands
    .command('help')
    .description('Print out this message')
    .action(() => commands.outputHelp());
  commands
    .command('stop')
    .description('Stop all processing in the crawler')
    .action(() => configureCount(0));
  commands
    .command('queue <requests...>')
    .option('-q, --queue <name>', 'The queue onto which the requests are pushed')
    .description('Queue the given list of orgs and/or repos and/or users to be processed.')
    .action((requests, options) => queueRequests(requests, options));
  commands
    .command('start [count]')
    .description('Start the crawler processing request with [count] concurrency')
    .action(count => configureCount(count || 1));
  commands
    .command('orgs <orgs...>')
    .description('Configure the crawler to process requests from only the given GitHub organizations')
    .action(orgs => configureOrgs(orgs));
  commands
    .command('config')
    .description('Dump the current crawler configuration to the console')
    .action(dumpConfig);
  commands
    .command('tokens <tokens...>')
    .description('Set the GitHub tokens to be used by the crawler. The parameter is a list of <token>#<trait>[,<trait>]* where the possible traits are "admin", "public", and "private"')
    .action(tokens => setTokens(tokens));
  commands
    .command('listtokens')
    .description('List GitHub tokens being used by the crawler.')
    .action(getTokens);
  commands
    .command('deadletters')
    .option('-c, --count', 'Count all deadletters')
    .option('-l, --list', 'List all deadletters')
    .option('-r, --requeue [urn]', 'Requeue deadletter with given urn.  Requeue all if no urn specified.')
    .option('-d, --delete <urn>', 'Delete the deadletter with the given urn')
    .description('Manage deadletters')
    .action(options => deadletters(options));
  commands
    .command('events <url>')
    .option('-z, --test', 'Test mode.  Process but do not actually queue the events.')
    .description('Backfill the events in the resource at the URL. The resource is assumed to be one JSON object per line')
    .action((url, options) => queueEvents(url, options));
  commands
    .command('exit')
    .description('Exit this tool')
    .action(() => process.exit(0));
  return commands;
}

function startReplLoop(commands) {
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout
  });

  rl.setPrompt(crawlerClient.url + '> ');
  rl.prompt();

  rl.on('line', (line) => {
    const command = argSplit(line);
    // pad up the command line to keep commander happy
    command.unshift('node', 'cc');
    commands.parse(command);
    promise
      .catch(error =>
        console.log(error.message))
      .finally(() => {
        promise = Q();
        rl.prompt();
      });
  });
}

function configureCount(count) {
  count = Math.max(count, 0);
  const patch = [
    { op: 'replace', path: '/crawler/count', value: count }
  ];
  promise = crawlerClient.configureCrawler(patch).then(() => console.log(`${count ? 'Started' : 'Stopped'} crawler processing`));
}

function configureOrgs(orgs) {
  const patch = [
    { op: 'replace', path: '/crawler/orgList', value: orgs }
  ];
  promise = crawlerClient.configureCrawler(patch).then(() => console.log('Configured org list'));
}

function dumpConfig() {
  promise = crawlerClient.getConfiguration().then(config => console.dir(config));
}

function setTokens(tokens) {
  promise = crawlerClient.setTokens(tokens).then(() => console.log('Tokens set'));
}

function getTokens() {
  promise = crawlerClient.getTokens().then(tokens => console.log(tokens.map(t => {
    return `${t.value}#${t.traits.join(",")}`
  }).join("\n")));
}

function queueRequests(specs, options) {
  let requests = Array.isArray(specs) ? specs : [specs];
  requests = requests.map(request => request.trim().startsWith('{') ? JSON.parse(request) : request);
  promise = crawlerClient.queueRequests(requests, options.queue).then(() => console.log(`Queued ${requests.length} requests`));
}

function deadletters(options) {
  if (options.count) {
    return countDeadletters();
  }
  if (options.list) {
    return listDeadletters();
  }
  if (options.requeue) {
    if (options.requeue === true) {
      return requeueDeadletters();
    }
    return requeueDeadletter(options.requeue);
  }
  if (options.delete) {
    return deleteDeadletter(options.delete);
  }
}

function countDeadletters() {
  promise = crawlerClient.getDeadletterCount().then(count => {
    console.log(`There are ${count} deadletters`);
  });
}

function listDeadletters() {
  promise = crawlerClient.listDeadletters().then(deadletters => {
    for (let i = 0; i < deadletters.length; i++) {
      const deadletter = deadletters[i];
      console.log(`${deadletter.extra.type} ${deadletter.extra.url} ${deadletter.extra.reason}`);
    }
  });
}

function requeueDeadletters() {
  promise = crawlerClient.listDeadletters().then(deadletters => {
    return Q.all(deadletters.map(qlimit(10)(deadletter => {
      return crawlerClient.requeueDeadletter(deadletter.urn);
    }))).then(() =>
      console.log(`Requeued all deadletters`));
  });
}

function requeueDeadletter(urn) {
  promise = crawlerClient.requeueDeadletter(urn).then(() => console.log(`Requeued ${urn}`));
}

function deleteDeadletter(urn) {
  promise = crawlerClient.deleteDeadletter(urn).then(() => console.log(`Deleted ${urn}`));
}

function queueEvents(url, options) {
  let requests = [];
  let count = 0;
  let bytes = 0;
  const response = request(url);
  response
    .pipe(split())
    .on('data', (line) => {
      const request = createEventRequest(line);
      if (!request) {
        return;
      }
      bytes += line.length;
      requests.push(request);
      if (requests.length === 10 && !options.test) {
        const toQueue = requests.slice();
        requests = [];
        response.pause();
        count += 10;
        crawlerClient.queueRequests(toQueue, 'later').then(
          () => {
            console.log(`Queued ${count} events and ${bytes} bytes so far...`);
            response.resume();
          },
          error =>
            console.log(error)
        );
      }
    })
    .on('error', error => {
      console.log(error);
    })
    .on('end', () => {
      crawlerClient.queueRequests(requests, 'later').then(
        () => {
          console.log(`Queued ${count + requests.length} events and ${bytes} bytes`);
        },
        error =>
          console.log(error)
      ).finally(() =>
        console.log('Done'));
    });
}

function createEventRequest(line) {
  try {
    const event = JSON.parse(line);
    delete event._id;
    const eventUrlBase = event.repo ? event.repo.url : event.org.url;
    const request = { type: event.type, url: `${eventUrlBase}/events/${event.id}` };
    request.payload = { body: event, etag: 1 };
    if (event.created_at) {
      request.payload.fetchedAt = event.created_at;
    }
    request.policy = 'default:self';
    return request;
  } catch (error) {
    console.log(error);
    return null;
  }
}